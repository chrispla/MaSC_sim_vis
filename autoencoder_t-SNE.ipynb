{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"autoencoder.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"source":["# 2D t-SNE from Autoencoder bottleneck using mel spectrogram\n","### from 15sec-from-the-middle audio dataset\n","\n","#### Visualization using vega and altair\n","\n","pip install vega\n","\n","pip install altair vega_datasets"],"cell_type":"markdown","metadata":{}},{"source":["### For working on Google drive"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"JwpI9CXNativ","colab_type":"code","outputId":"b568bb61-0554-4a9a-a7b2-7556ebb533dd","executionInfo":{"status":"ok","timestamp":1562422481209,"user_tz":-240,"elapsed":1197,"user":{"displayName":"Christos Plachouras","photoUrl":"https://lh5.googleusercontent.com/-18ydN9PceMg/AAAAAAAAAAI/AAAAAAAAP7I/VKtWnT_L5lI/s64/photo.jpg","userId":"12211369927103733128"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"source":["### Importing"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"GQVbXxwZhpUw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"eefe07e0-c9f0-468e-f6ec-de0c943964a2","executionInfo":{"status":"ok","timestamp":1562424242943,"user_tz":-240,"elapsed":5297,"user":{"displayName":"Christos Plachouras","photoUrl":"https://lh5.googleusercontent.com/-18ydN9PceMg/AAAAAAAAAAI/AAAAAAAAP7I/VKtWnT_L5lI/s64/photo.jpg","userId":"12211369927103733128"}}},"source":["import glob\n","import numpy as np\n","import librosa\n","import os\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import vega\n","import altair as alt\n","import pandas as pd\n","import scipy.signal\n","import scipy.fftpack as fft\n","from keras.layers import Input, Dense\n","from keras.models import Model"],"execution_count":null,"outputs":[]},{"source":["### Read audio"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#File reading\n","print('File reading...')\n","all_dirs = []\n","for root, dirs, files in os.walk('/content/drive/My Drive/MaSC Research/Datasets/Test0'):\n","        for name in files:\n","            if '.wav' in name:\n","                filedir = os.path.join(root, name)\n","                all_dirs.append(filedir)\n","file_no = len(all_dirs)\n","print('Number of files: ' + str(file_no))"]},{"source":["### Compute mel spectrograms"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"m9ZuTAFfbKQy","colab_type":"code","outputId":"62df96ec-ea03-4b5b-92e8-4a066504c065","executionInfo":{"status":"error","timestamp":1562424750577,"user_tz":-240,"elapsed":54747,"user":{"displayName":"Christos Plachouras","photoUrl":"https://lh5.googleusercontent.com/-18ydN9PceMg/AAAAAAAAAAI/AAAAAAAAP7I/VKtWnT_L5lI/s64/photo.jpg","userId":"12211369927103733128"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Feature Computation\n","print('Feature Computation...')\n","all_db = []\n","all_mean = []\n","file_names = []\n","\n","for i in range(file_no):\n","    #only consider audio that is exactly 15seconds \n","    if (librosa.get_duration(filename=all_dirs[i]) == 15.):\n","        file_names.append(all_dirs[i])\n","\n","        #Load file\n","        y, sr = librosa.core.load(all_dirs[i], duration=10.)\n","\n","        #Features\n","        S = librosa.core.stft(y=y)\n","        S_db = librosa.core.power_to_db(np.abs(S)**2)\n","        all_mean.append(np.mean(S_db)) \n","        \n","        S_mel = librosa.feature.melspectrogram(y=y, sr=sr)\n","        all_db.append(S_mel.flatten()) #length: 82688\n","\n","    sys.stdout.write(\"\\rLoading %i recordings.\" % (i))\n","    sys.stdout.flush()\n","\n","feature_no = len(all_db[0])      \n","\n","print('Number of files with a duration of 15 seconds: ' + str(len(file_names)))"],"execution_count":null,"outputs":[]},{"source":["### Train-Test Split"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(np.asarray(all_db), np.asarray(file_names), test_size=0.1, random_state=42)\n","print(X_train.shape)"]},{"source":["### Model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Autoencoder (2000, 100, 50, 100, 2000, 82688)\n","input_db = Input(shape=(feature_no,))\n","encoded = Dense(2000, activation='relu')(input_db)\n","encoded = Dense(100, activation='relu')(encoded)\n","encoded = Dense(50, activation='relu')(encoded)\n","decoded = Dense(100, activation='relu')(encoded)\n","decoded = Dense(2000, activation='relu')(decoded)\n","decoded = Dense(feature_no, activation='relu')(decoded)\n","\n","autoencoder = Model(input_db, decoded)\n","encoder = Model(input_db, encoded)\n","autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"]},{"source":["### Training"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["autoencoder.fit(X_train, X_train,\n","                epochs=50,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_split = 0.2,\n","                validation_data=(X_test, X_test))\n","encoded_db = encoder.predict(X_train)"]},{"source":["### Visualize"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Standardization\n","scl1 = StandardScaler()\n","all_db_scaled = scl1.fit_transform(encoded_db)\n","\n","#TSNE\n","db_red2 = TSNE(n_components=2).fit_transform(all_db_scaled)\n","\n","#KMeans\n","kmeans = KMeans(n_clusters=5, random_state=0).fit(db_red2)\n","clusters = kmeans.predict(db_red2)\n","\n","#axis dataframes\n","db1 = []\n","db2 = []\n","for i in range(len(db_red2)):\n","    mel1.append(db_red2[i][0])\n","    mel2.append(db_red2[i][1])\n","\n","#Clusters\n","df1 = pd.DataFrame({'x': np.asarray(db1), 'y': np.asarray(db2), 'color': clusters, 'path': np.asarray(y_train), 'filename': np.asarray(y_train)})\n","chart1 = alt.Chart(df).mark_circle(opacity=0.6, size=60).encode(x='x', y='y', color='color:N', href='path', tooltip=['filename']).interactive()\n","\n","#Also make an Intensity graph\n","df2 = pd.DataFrame({'x': np.asarray(db1), 'y': np.asarray(db2), 'color': all_mean, 'path': np.asarray(y_train), 'filename': np.asarray(y_train)})\n","chart2 = alt.Chart(df).mark_circle(opacity=0.6, size=60).encode(x='x', y='y', color='color:Q', href='path', tooltip=['filename']).interactive()\n","\n","#Combined AE Clusters + Intensity\n","df3 = pd.DataFrame({'x': np.asarray(db1), 'y': np.asarray(db2), 'color': clusters, 'path': np.asarray(y_train), 'filename': np.asarray(y_train)})\n","chart3 = alt.Chart(df).mark_circle(size=80).encode(x='x', y='y', color='color:N', href='path', tooltip=['filename']).interactive()\n","df4 = pd.DataFrame({'x': np.asarray(db1), 'y': np.asarray(db2), 'color': all_mean, 'path': np.asarray(y_train), 'filename': np.asarray(y_train)})\n","chart2 = alt.Chart(df).mark_circle(size=30).encode(x='x', y='y', color='color:Q', href='path', tooltip=['filename']).interactive()\n","\n","display(chart1)\n","display(chart2)\n","display(chart3 + chart4)"]}]}