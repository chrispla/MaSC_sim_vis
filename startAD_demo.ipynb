{
 "cells": [
  {
   "source": [
    "# MFCC and Chroma Visualization\n",
    "Computing MFCC and Chroma, reducing their dimenionality using PCA, and plotting each at one axis while controlling their spread. Script for StartAD demo visualization, traversing similarity at two perpendicular, independent axes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import vega\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import scipy.fftpack as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "source": [
    "### Reading audio paths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File reading\n",
    "all_dirs = []\n",
    "for root, dirs, files in os.walk('./Test'):\n",
    "        for name in files:\n",
    "            if '.wav' in name:\n",
    "                filedir = os.path.join(root, name)\n",
    "                all_dirs.append(filedir)"
   ]
  },
  {
   "source": [
    "### Computing features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chroma = []\n",
    "all_mfcc = []\n",
    "file_no = len(all_dirs)\n",
    "print(file_no)\n",
    "for i in range(file_no):\n",
    "    print(str(i+1) + '/' + str(file_no))\n",
    "    #Load file\n",
    "    y, sr = librosa.core.load(all_dirs[i])\n",
    "    #Features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr, n_chroma=48, n_octaves=7)\n",
    "    all_mfcc.append(mfcc.flatten())\n",
    "    all_chroma.append(chroma.flatten())\n",
    "\n",
    "#Standardization\n",
    "scl1 = StandardScaler()\n",
    "all_mfcc_scaled = scl1.fit_transform(all_mfcc)\n",
    "scl2 = StandardScaler()\n",
    "all_chroma_scaled = scl2.fit_transform(all_chroma)"
   ]
  },
  {
   "source": [
    "### Dimensionality reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC2\n",
    "pca_mfcc2 = PCA(n_components=2).fit_transform(all_mfcc_scaled)\n",
    "scl3 = StandardScaler()\n",
    "pca_mfcc2 = scl3.fit_transform(pca_mfcc2)\n",
    "pca_mfcc2x = []\n",
    "pca_mfcc2y = []\n",
    "for i in range(pca_mfcc2.shape[0]):\n",
    "    pca_mfcc2x.append(pca_mfcc2[i][0])\n",
    "for i in range(all_mfcc_scaled.shape[0]):\n",
    "    pca_mfcc2y.append(pca_mfcc2[i][1])\n",
    "\n",
    "#MFCC1\n",
    "pca_mfcc = PCA(n_components=1).fit_transform(all_mfcc_scaled)\n",
    "scl4 = StandardScaler()\n",
    "pca_mfcc = scl4.fit_transform(pca_mfcc)\n",
    "pca_mfcc1 = []\n",
    "for i in range(pca_mfcc.shape[0]):\n",
    "    pca_mfcc1.append(pca_mfcc[i][0])\n",
    "\n",
    "#CHROMA1\n",
    "pca_chroma = PCA(n_components=1).fit_transform(all_chroma_scaled)\n",
    "scl5 = StandardScaler()\n",
    "pca_chroma = scl5.fit_transform(pca_chroma)\n",
    "pca_chroma1 = []\n",
    "for i in range(pca_chroma.shape[0]):\n",
    "    pca_chroma1.append(pca_chroma[i][0])\n",
    "\n",
    "#Dimensionality reduction\n",
    "all_mfcc_scaled_red = TSNE(n_components=1, perplexity = 10.0).fit_transform(all_mfcc_scaled)\n",
    "all_chroma_scaled_red = TSNE(n_components=1, perplexity = 10.0).fit_transform(all_chroma_scaled)\n",
    "print('Computation complete.')"
   ]
  },
  {
   "source": [
    "### Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for i in range(len(all_mfcc_scaled_red2)):\n",
    "    x.append(all_mfcc_scaled_red2[i][0])\n",
    "for i in range(len(all_mfcc_scaled_red2)):\n",
    "    y.append(all_mfcc_scaled_red2[i][1])\n",
    "for i in range(len(all_chroma_scaled_red1)):\n",
    "    z.append(all_mfcc_scaled_red2[i][0])\n",
    "print(pca_chroma1)\n",
    "\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "for i in range(len(pca_mfcc2x)):\n",
    "    feature1.append('mfcc')\n",
    "for i in range(len(pca_mfcc1)):\n",
    "    feature2.append('chroma')\n",
    "    \n",
    "df1 = pd.DataFrame({'x': np.asarray(pca_mfcc2x), 'y': np.asarray(pca_mfcc2y)/5, 'color': np.asarray(feature1)})\n",
    "df2 = pd.DataFrame({'x': ((np.asarray(pca_mfcc1)/7)-0.1), 'y': np.asarray(pca_chroma1), 'color': np.asarray(feature2)})\n",
    "df3 = pd.DataFrame({'x': np.asarray(pca_mfcc2x), 'y': np.asarray(pca_mfcc2y)/2, 'color': np.asarray(feature1)})\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "viz1 = alt.Chart(df1).mark_circle(opacity=0.6, size=60).encode(x='x', y='y', color='color:N').interactive()\n",
    "#.configure_mark(opacity=0.5, color='cyan').interactive()\n",
    "viz2 = alt.Chart(df2).mark_circle(opacity=0.6, size=60).encode(x='x', y='y', color='color:N').interactive()\n",
    "#.configure_mark(opacity=0.5, color='magenta').interactive()\n",
    "viz1+viz2\n",
    "#viz3 = alt.Chart(df3).mark_circle(opacity=0.0, size=60).encode(x='x', y='y', color='color:N').interactive()\n",
    "#viz2+viz3\n",
    "#x=alt.X('x:Q', title='MFCC1'),\n",
    "#y=alt.Y('y:Q', title='MFCC2'),\n",
    "#z=alt.Z('z:Q', title='CHROMA')).add_selection(brush)\n",
    "#alt.condition(brush, 'location:N', alt.value('grey')),\n",
    "#     tooltip=['filename', 'location', 'ethnic_group', 'original_format', 'recorded_from_date', 'recording_context', ],\n",
    "#     href='local_path'\n",
    "\n",
    "#plt.scatter(np.asarray(pca_mfcc2x), np.asarray(pca_mfcc2y)/3, c='c', alpha=0.5)\n",
    "#plt.scatter(np.asarray(pca_mfcc1)/8, np.asarray(pca_chroma1), c='m', alpha=0.5)\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}